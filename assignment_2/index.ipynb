{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (1.23.4)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: surprise in /usr/local/lib/python3.9/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.9/site-packages (from surprise) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.9.3)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "import sys\n",
    "!{sys.executable} -m pip install surprise\n",
    "\n",
    "from surprise import Dataset, SlopeOne, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "trainset, testset= train_test_split(data, test_size=.30)\n",
    "\n",
    "algo= SlopeOne()\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions= algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9476578603608544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions, verbose=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c:\n",
    "\n",
    "* Random splitting: Testset 20% Trainset 80%, weil man häufig 20-30% zum Testen und 70-80% verwendet (https://scholarworks.utep.edu/cs_techrep/1209/) <br><br>\n",
    "* RMSE: \n",
    "    * Vorteil, dass große Fehler stärker bestraft werden\n",
    "    * Man sieht besser ob das Modell viele Ausreißer hat, um diese zu reduzieren\n",
    "    * MAE zu einfach um Gesamtleistung des Modells zu verstehen\n",
    "                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est, true_r))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 20 werden folgende Filme vorgeschlagen: ['22', '210', '69', '204', '423', '378', '274', '118', '94', '252']\n"
     ]
    }
   ],
   "source": [
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "#get the user 310 with the recommended films\n",
    "#print(top_n.get('310'))\n",
    "def getUserAndMovie(user):\n",
    "    movie = []\n",
    "    for i in top_n.get(user):\n",
    "        movie.append(i[0])\n",
    "    #print(\"User {} has the .\".format(user))\n",
    "    print(\"User {} werden folgende Filme vorgeschlagen: {}\".format(user,movie))\n",
    "\n",
    "getUserAndMovie('20')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all Recommendations for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllRecommendatios(predictions):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est, true_r))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all recommendations for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('22', 3.564153676698129, 5.0), ('210', 3.36244635643561, 4.0), ('69', 3.2728598907785185, 1.0), ('204', 3.2603642699937283, 3.0), ('423', 3.193303459010281, 2.0), ('378', 3.080074257285008, 3.0), ('274', 2.773948413969998, 4.0), ('118', 2.521080941185077, 4.0), ('94', 2.474361414040916, 2.0), ('252', 2.1691555586020193, 4.0), ('820', 2.157641786042335, 2.0), ('678', 1.9483057827760566, 4.0), ('243', 1.7199587197784834, 4.0), ('931', 1.414324391316733, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "def getRecommendations(user):\n",
    "    return getAllRecommendatios(predictions).get(user)\n",
    "\n",
    "print(getRecommendations('20'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: e\n",
    "\n",
    "Zuerst haben wir ein Dictionary erstellt, welches mit der UserID, dem geschätzten Wert und dem tatsächlichen Werten befüllt wurde. Anschließend wurde die Liste mit den vorgeschlagenen Filmen absteigend nach dem Wert der recommendation sortiert. All zweite Funktion wurde eine Liste mit allen Usern und deren Filmen erstellt. Nun können wir für einen bestimmten User alle Filme mit den dazugehörigen Werten (tatsächliches Rating, ausgerechneter Wert) ausgeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: Calculate precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 2 – Implementierung von Precision und Recall\n",
    "a) Implementieren Sie eine Funktion, um die Precision basierend auf Ihrem Testest aus Aufgabe 1 zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items relevant: 5\n",
      "Items recommended: 7\n",
      "Precision: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def isItemRelevant(item):\n",
    "    if item[2]>=3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def calcPrecision(rec):\n",
    "    relevantScore = 0\n",
    "    for i in range(math.floor(len(rec)/2)):\n",
    "        if isItemRelevant(rec[i]):\n",
    "            relevantScore+=1\n",
    "\n",
    "    print(\"Items relevant: {}\".format(relevantScore))\n",
    "    print(\"Items recommended: {}\".format(math.floor(len(rec)/2)))\n",
    "    return relevantScore/math.floor(len(rec)/2)\n",
    "\n",
    "print(\"Precision: {}\".format(calcPrecision(getRecommendations('20'))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: b\n",
    " Implementieren Sie eine Funktion, um den Recall basierend auf Ihrem Testest aus Aufgabe 1 zu berechnen. Welche Annahmen haben Sie dafür getroffen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recommended relevant: 5\n",
      "All relevant items: 9\n",
      "Recall: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "def isItemRelevant(item, x=3):\n",
    "    if item[2]>=x:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def calcRecall(rec):\n",
    "    relevantScore = 0\n",
    "    allRelevantScore = 0\n",
    "    for i in range(math.floor(len(rec)/2)):\n",
    "        if isItemRelevant(rec[i]):\n",
    "            relevantScore+=1\n",
    "\n",
    "    for i in range(len(rec)):\n",
    "        if isItemRelevant(rec[i]):\n",
    "            allRelevantScore+=1\n",
    "\n",
    "    print(\"Items recommended relevant: {}\".format(relevantScore))\n",
    "    print(\"All relevant items: {}\".format(allRelevantScore))\n",
    "    return relevantScore/allRelevantScore\n",
    "\n",
    "print(\"Recall: {}\".format(calcRecall(getRecommendations('20'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7209139187665161\n",
      "0.47283200998455716\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls =  precision_recall_at_k(predictions)\n",
    "print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uns fällt auf, dass die Werte für Precision und Recall sehr ähnlich zu unseren Werten sind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3:\n",
    "a) Wiederholen Sie die Experimente aus Aufgabe 1 und Aufgabe 2 mit dem Book-Crossing Dataset3. Sie können auch gerne einen anderen Algorithmus dafür anwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import Dataset, Reader, SlopeOne\n",
    "from surprise.model_selection import train_test_split\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser(\"./BX-Book-Ratings.csv\")\n",
    "\n",
    "reader = Reader(line_format=\"user item rating\", sep=\";\",rating_scale=(1,10))\n",
    "\n",
    "data2 = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "algo2 = SVD()\n",
    "\n",
    "for trainset2, testset2 in kf.split(data2):\n",
    "    algo2.fit(trainset2)\n",
    "    predictions2 = algo.test(testset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.5048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.504789015151917"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions, verbose=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 300 werden folgende Bücher vorgeschlagen: ['0449912302', '038081840X', '0312963009']\n"
     ]
    }
   ],
   "source": [
    "top_n2 = get_top_n(predictions, n=10)\n",
    "\n",
    "#get the user 310 with the recommended films\n",
    "#print(top_n2.get('300'))\n",
    "def getUserAndBook(user):\n",
    "    book = []\n",
    "    for i in top_n2.get(user):\n",
    "        book.append(i[0])\n",
    "    #print(\"User {} has the .\".format(user))\n",
    "    print(\"User {} werden folgende Bücher vorgeschlagen: {}\".format(user,book))\n",
    "\n",
    "getUserAndBook('300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllBookRecommendatios(predictions):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est, true_r))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2702400612', 5, 7.0), ('2253144452', 5, 9.0), ('2253152072', 5, 9.0), ('8484601072', 1.9759995229945346, 0.0), ('059035342X', 1, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "def getBookRecommendations(user):\n",
    "    return getAllBookRecommendatios(predictions2).get(user)\n",
    "\n",
    "print(getBookRecommendations('276939'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items relevant: 2\n",
      "Items recommended: 2\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {}\".format(calcPrecision(getBookRecommendations('276939')),x=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recommended relevant: 2\n",
      "All relevant items: 3\n",
      "Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}\".format(calcRecall(getBookRecommendations('276939')),x=6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
